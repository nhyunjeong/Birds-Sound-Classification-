**개발환경**
![SOUND_DNN_개발환경](https://user-images.githubusercontent.com/95748637/196600641-88bc1511-3f2b-4146-a836-a02fb9645b0c.png)

## 목차

1. 구현 목표 & 개요 
2. 음성데이터의 이해 
소리의 3요소 
푸리에 변환 
MFCC
Zero Crossing Rate 
3. 데이터 준비 & 소개 
4. 데이터 구성 & 전처리 
	- ogg -> wav 파일 변환 
5. 신경망 구성전 작업
	라벨링 
	훈련 & 검증 데이터
	one hot encoding 
6. sound wave 시각화 
7. 152종 신경망 구성 & 결과
8. 6종만 가지고 신경망 재구성 & 결과 (데이터 불균형 문제없는 데이터) 
9. 결론 


## 1. 구현 목표 & 개요 

### 구현목표 
하와이 섬 전역에 남아있는 많은 새들은 접근하기 어렵고 고도가 높은 서식지에 위치하여 시각적 모니터링이 어려운 상황이다.   
따라서 과학자들은 사운드로 모니터링을 하려고 한다.   
신경망기술을 이용하여 사운드로 조류를 구분하여 모니터링이 가능하게 되면 멸종 위기에 처한 조류의 보호가 가능해 질 뿐만아니라 생물 음향 기술의 발전을 기대할 수 있다. 

### 개요 
인공신경망을 사용하여 새 소리를 학습시킨 모델을 생성한 후 새 종별 소리 분류 인터페이스 구현하기
		
## 2. 음성데이터의 이해 
- 소리의 3요소 
- 푸리에 변환   
https://no-loo.tistory.com/119?category=1095719

- MFCC
- Zero Crossing Rate   
https://no-loo.tistory.com/120?category=1095719

## 3. 데이터 준비 & 소개  
###  캐글에서 데이터 셋 받아오기 
[캐글링크](https://www.kaggle.com/competitions/birdclef-2022)
### 데이터 소개 
- 하와이의 새 의 68% 가 멸종되었다.
- 폴더에 152 종 의 새가 있다
- 총 ogg 파일형식으로 되어있으며 14852개의 sound data 존재한다.
- **불균형이 심한 데이터이다.**



## 4. 데이터 구성 & 전처리 (jupyter notebook) 
1. 메타 데이터 살펴보기
2. 새 종이 몇종인지 살펴보기 & 이름 추출하기 
3. 새 종별 각각 몇개의 음원 데이터 갖고있는지 보기 
	(data frame 형태 -> sound data 개수 높은 순 정렬) 
4. 종 별 데이터 분포사항 

- ogg -> wav 파일 변환 
	
	
## 5. 신경망 구성전 작업
- 라벨링 
- 훈련 & 검증 데이터
- one hot encoding  
	
## 6. sound wave 시각화 살펴보기
- wave 시각화 (1개 & 12개) 
	![SOUND Waves](https://user-images.githubusercontent.com/95748637/196601165-2d479bf4-247e-4cb2-b5e4-a5be2f177a9a.png)   
	- 종별로 다양한 형태의 wave 형태를 가지고 있다. 
	
- spectrogram 

	![spectogram](https://user-images.githubusercontent.com/95748637/196601156-e4bbe4f9-efd2-4c90-ad12-00d2f0844e7e.png)
	- 시간의 3~4 범위 중 2000 hz (낮은소리범위) 의 작은 소리의 값이 특징인것으로 보인다.
	- 고속 푸리에 변환 인 (FFT) 를 시행하여 각 주파수의 대역별 세기를 살펴 볼 수 있다.
	- 어떤 주파수가 강하고 약한지에 대한 정보를 얻을 수 있음 
	- 즉 Spectrum 에서 소리 고유의 특징을 추출 할 수 있다. 
	
- Mel Spectrogram 

	![Mel Spectogram](https://user-images.githubusercontent.com/95748637/196601142-5c006e0d-ce01-46ee-8f0a-e54ea4ed2aaa.png)
	- MFCC 를 위해 일반 Spectrum 이 아닌 특수한 필터인 Mel Spectrum(실제 사람이 인식하는 주파수의 관계를 표현한것) 에 Cepstral 분석을 적용해 추출한다. 

	
- Mfcc

	![MFCC](https://user-images.githubusercontent.com/95748637/196601147-3e6343e6-b338-4f8e-bb43-de5819bf609d.png)
	- Cepstral 배음 구조를 유추해 내어 소리 고유한 특징을 찾아내는것 

	
	
	
## 7. 152종 신경망 구성 & 결과
### 기본세팅 값
1. epochs : 200
2. batch size : 50 
3. 완전연결 3층 신경망 
4. 배치정규화 사용 
5. drop out 비율 :  0.2  
6. 얼리스탑핑 기능 True ,  patience = 20
7. Adam
8. ReLU

- 신경망 과정 이미지화 

- 결과표 보기 

152 종을 모두 분류하는 신경망의 최대 정확도는 0.48 , 0.32 로 매우 안좋은 성능을 보였다.   
그 이유로는 앞서 데이터를 살펴보았을때 클래스당 존재하는 데이터 갯수의 불균형이 매우 심했던 영향때문인것으로 예상된다. 

그렇다면 데이터의 갯수가 같고 많은 새의 종류들만 가지고 신경망 모델을 재구성하여 정확도를 살펴보려고한다. 
	
## 8. 6종만 가지고 신경망 재구성 & 결과 (데이터 불균형 문제없는 데이터) 
### 기본세팅 값
1. epochs : 200
2. batch size : 30
3. 완전연결 6층 신경망 
4. 배치정규화 사용 x 
5. drop out 비율 :  0.1
6. 얼리스탑핑 기능 True ,  patience = 20
7. Adam
8. ReLU
	
## 9. 결론 
맨 처음 152종을 모두 분류 하는 신경망은 활성화 함수 ReLU 와 경사하강법 Adam 을 사용하는것이 가장 좋은 결과를 나타냈다. 

그러나 훈련정확도는 50을 넘기지 못하고 테스트 데이터 정확도는 40을 넘지못하는 문제가 있어서 데이터의 균형이 맞는 조류들만 따로 뽑아  **brnowl,  skylar, norcar, mallar3 ,houspa, comsan 의 6종만 먼저 분류하여 신경망을 구성하였다.** 

그 결과 훈련 데이터의 정확도가 최대 0.70 로 많이 향상되었고 테스트 데이터의 정확도 또한 최대 0.59 까지 향상되었다. 
훈련데이터의 정확도가 높을 때에는 오버피팅이 많이 발생되어서 drop out 을 적용해 주었는데 그럴때에는 훈련데이터의 정확도가 다소 떨어지긴했지만 대신 테스트 데이터의 정확도는 조금 향상되고 서로의 정확도 간극이 줄어드는것을 확인 할 수 있었다. 

또한 뉴런의 갯수가 많을 수록 정확도가 높아지는 경향을 보여 신경망을 구성할 때 조금더 많은 뉴런수를 주는것과 **활성화 함수는 ReLU**, **경사하강법은 Adam** 을 사용하여 매개변수들을 조정하면 더 정확도를 높일 수 있을것으로 생각 된다.
